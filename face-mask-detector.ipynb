{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from PIL import Image\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "#For model\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "#For shwing images and graphs\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('cloth_mask', 'mask_worn_incorrectly', 'n95_mask', 'no_mask', 'surgical_mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePath = 'Classes/'\n",
    "transform = transforms.Compose([transforms.Resize((128,128)), transforms.ToTensor()])#Just resizing the image to 128*128 size\n",
    "\n",
    "data = datasets.ImageFolder(root=imagePath, transform=transform)\n",
    "\n",
    "loader = DataLoader(dataset=data,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image size normalization\n",
    "\n",
    "def get_mean_and_std(dataloader):\n",
    "    channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
    "    for data, _ in dataloader:\n",
    "        # Mean over batch, height and width, but not over the channels\n",
    "        #print(len(data))\n",
    "        #print(data)\n",
    "        channels_sum += torch.mean(data, dim=[0,2,3])\n",
    "        channels_squared_sum += torch.mean(data**2, dim=[0,2,3])\n",
    "        num_batches += 1\n",
    "    \n",
    "    mean = channels_sum / num_batches\n",
    "\n",
    "    # std = sqrt(E[X^2] - (E[X])^2)\n",
    "    std = (channels_squared_sum / num_batches - mean ** 2) ** 0.5\n",
    "\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = get_mean_and_std(loader)\n",
    "print('Before normalization:')\n",
    "print('Mean: '+  str(mean))\n",
    "print('Standard Dev: '+  str(std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((128,128)), transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=mean,std=std)])\n",
    "data = datasets.ImageFolder(root=imagePath, transform=transform)\n",
    "\n",
    "\n",
    "loader = DataLoader(data,batch_size=32)\n",
    "new_mean, new_std = get_mean_and_std(loader)\n",
    "print('After normalization:')\n",
    "print('Mean: '+  str(new_mean))\n",
    "print('Standard Dev: '+  str(new_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(data))\n",
    "test_size = len(data) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(data, [train_size, test_size], generator=torch.Generator().manual_seed(42))\n",
    "#print('Train size: ' + str(len(train_dataset)))\n",
    "#print('Test size: ' + str(len(test_dataset)))\n",
    "train_loader = DataLoader(train_dataset,batch_size=32)\n",
    "validation_loader = DataLoader(data,batch_size=32)\n",
    "test_loader = DataLoader(test_dataset,batch_size=32)\n",
    "\n",
    "# #Delete this later\n",
    "# batch =next(iter(validation_loader))\n",
    "# images,labels=batch\n",
    "# grid=torchvision.utils.make_grid(images,nrow=3)\n",
    "# plt.figure(figsize=(11,11))\n",
    "# plt.imshow(np.transpose(grid,(1,2,0)))\n",
    "# print('labels',labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.convlayers =  nn.Sequential(\n",
    "            nn.Conv2d(3,32,3,padding=1), nn.BatchNorm2d(32), nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(32,64,3,padding=1), nn.BatchNorm2d(64), nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(64,128,3,padding=1), nn.BatchNorm2d(128), nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2,2)\n",
    "        )\n",
    "        self.FC = nn.Sequential(\n",
    "            nn.Linear(128*16*16,100),\n",
    "            nn.Linear(100,5)\n",
    "            \n",
    "        )\n",
    "    \n",
    "    def forward(self,X):\n",
    "        X = self.convlayers(X)\n",
    "        X =  self.FC(X.reshape(-1,128*16*16))\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = ConvNet()\n",
    "optimizer = optim.Adam(cnn.parameters(),lr=0.00001)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "epochs = 1\n",
    "training_losses = []\n",
    "validation_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(epochs, epochs+25):\n",
    "    cnn.train()\n",
    "    training_loss=0\n",
    "    for i, (batch,labels) in enumerate(train_loader):\n",
    "        y_h = cnn(batch)\n",
    "        cnn.zero_grad()#for every mini-batch during the training phase, we typically want to explicitly set the gradients to zero before starting to do backpropragation \n",
    "        training_loss = loss_func(y_h,labels)#A loss function is a function that compares the target and predicted output values; measures how well the neural network models the training data. When training, we aim to minimize this loss between the predicted and target outputs.\n",
    "        training_loss.backward()#Computes the gradient of current tensor w.r.t. graph leaves. The graph is differentiated using the chain rule. If the tensor is non-scalar (i.e. its data has more than one element) and requires gradient, the function additionally requires specifying gradient .\n",
    "        optimizer.step()#Performs a single optimization step (parameter update). Parameters: closure (Callable) â€“ A closure that reevaluates the model and returns the loss.\n",
    "    training_losses.append(training_loss)\n",
    "\n",
    "    cnn.eval()\n",
    "    validation_loss=0\n",
    "    for i, (batch,labels) in enumerate(validation_loader):\n",
    "        with torch.no_grad():\n",
    "            y_h = cnn(batch)\n",
    "            validation_loss = loss_func(y_h,labels)\n",
    "    validation_losses.append(validation_loss)\n",
    "    print('Epoch:{}, training_loss:{}, validation_losses:{}'.format(e,training_loss,validation_loss))\n",
    "\n",
    "epochs+=10\n",
    "\n",
    "plt.figure()\n",
    "training_losses = [tl.detach().numpy() if torch.torch.is_tensor(tl) else tl for tl in training_losses]\n",
    "validation_losses = [vl.detach().numpy() if torch.torch.is_tensor(vl) else vl for vl in validation_losses]\n",
    "plt.plot(training_losses,label='Training Loss')\n",
    "plt.plot(validation_losses,label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Cross Entropy Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet_Variant1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.convlayers =  nn.Sequential(\n",
    "            nn.Conv2d(3,32,3,padding=1), nn.BatchNorm2d(32), nn.LeakyReLU(),\n",
    "            nn.Conv2d(32,32,3,padding=1), nn.BatchNorm2d(32), nn.LeakyReLU(),\n",
    "            nn.Conv2d(32,32,3,padding=1), nn.BatchNorm2d(32), nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(32,64,3,padding=1), nn.BatchNorm2d(64), nn.LeakyReLU(),\n",
    "            nn.Conv2d(64,64,3,padding=1), nn.BatchNorm2d(64), nn.LeakyReLU(),\n",
    "            nn.Conv2d(64,64,3,padding=1), nn.BatchNorm2d(64), nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(64,128,3,padding=1), nn.BatchNorm2d(128), nn.LeakyReLU(),\n",
    "            nn.Conv2d(128,128,3,padding=1), nn.BatchNorm2d(128), nn.LeakyReLU(),\n",
    "            nn.Conv2d(128,128,3,padding=1), nn.BatchNorm2d(128), nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2,2)\n",
    "        )\n",
    "        self.FC = nn.Sequential(\n",
    "            nn.Linear(128*16*16,100),\n",
    "            nn.Linear(100,5)\n",
    "            \n",
    "        )\n",
    "    \n",
    "    def forward(self,X):\n",
    "        X = self.convlayers(X)\n",
    "        X =  self.FC(X.reshape(-1,128*16*16))\n",
    "        return X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
